import requests
from bs4 import BeautifulSoup
import random

def test_hh_parser(job_title, city_name):
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º, —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏—Ö–æ–¥–∏—Ç —Å HH.ru"""

    city_mapping = {
        "–º–æ—Å–∫–≤–∞": "1",
        "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥": "2",
        "–∫—Ä–∞—Å–Ω–æ–¥–∞—Ä": "53",
        "–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥": "3",
        "–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫": "4"
    }

    city_id = city_mapping.get(city_name.lower())

    if not city_id:
        print("‚ö†Ô∏è –ì–æ—Ä–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω. –í–≤–µ–¥–∏—Ç–µ –¥—Ä—É–≥–æ–π –≥–æ—Ä–æ–¥.")
        return

    url = f"https://hh.ru/search/vacancy?text={job_title}&area={city_id}"
    
    headers = {
        "User-Agent": random.choice([
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36"
        ])
    }

    response = requests.get(url, headers=headers)

    if response.status_code != 200:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ HH.ru: {response.status_code}")
        return

    soup = BeautifulSoup(response.text, "html.parser")

    # üîπ –í—ã–≤–µ–¥–µ–º –≤–µ—Å—å HTML –≤ –∫–æ–Ω—Å–æ–ª—å
    print("\nüîπ HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—ã HH.ru (–ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤):\n")
    print(response.text[:1000])

if __name__ == "__main__":
    job_title = input("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏: ")
    city_name = input("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞: ")
    test_hh_parser(job_title, city_name)
